# Azure Databricks & Spark Core for Data Engineers (Python/SQL)

## ‚ùó Sobre o curso

### Objetivo
O objetivo deste curso √© realizar um projeto aplicado nos dados da F√≥rmula 1 utilizando os principais conceitos e ferramentas do mercado para realiza√ß√£o de ingest√£o, tratamento e disponibiliza√ß√£o dos dados de maneira automatizada focados em Big Data Analytics.

### üë®‚Äçüíª Sobre o Autor

O reposit√≥rio original pertence ao professor Ramesh Retnasamy no qual √© especialista em Arquitetura, Design, Desenvolvimento e Implementa√ß√£o de projetos de engenharia de dados e machine learning, atuando com Tecnologia da Informa√ß√£o desde 2002. 

LinkedIn: https://www.linkedin.com/in/ramesh-retnasamy/

### üí∞ Adquirindo o curso

O curso pode ser adquirido em: https://www.udemy.com/course/azure-databricks-spark-core-for-data-engineers/

## üìÑ  que √© abordado

Os principais aprendizados s√£o focados em Azure Databricks utilizando as linguagens PySpark e SparkSQL, por√©m √© poss√≠vel visualizar algumas ferramentas da azure, tais como Key Vault, Data Factory, Data Lake Storage Gen2.

### ‚öôÔ∏è Azure Databricks

O Databricks √© utilizado para processamentos de grandes volumes de dados, no qual apenas o Data Factory n√£o seria capaz de realizar os devidos tratamentos. Conta com uma gama de possibilidades, atrav√©s do framework spark, podendo utilizar integra√ß√µes e comunica√ß√µes entre as linguagens Spark SQL, PySpark, Scala e R.

### ‚öôÔ∏è Azure Data Factory

Principal ferramenta em cloud da Microsoft utilizada para tarefas de obten√ß√£o, ingest√£o e orquestra√ß√£o de dados. 

- Opera√ß√µes de debug, agendamentos por Event Trigger, Schedule Trigger e Tumbling Window Trigger. 
- Integra√ß√£o e orquestra√ß√£o com Databricks, Orquestra√ß√£o de todas as activites via pipeline. 


### üìÇ Azure Data Lake Storage Gen2

Ferramentas em cloud da Microsoft utilizadas para armazenamento de arquivos focados em Big Data, controle de acessos e centraliza√ß√£o de informa√ß√µes.

- Cria√ß√£o de Data Lake Gen2, Conainers, Upload de dados, IAM. 


- Cria√ß√£o de Workspace no Azure Databricks, cria√ß√£o de Clusters, realizando opera√ß√µes de mount em Storage Account, cria√ß√£o de notebooks, transforma√ß√µes via pyspark, requisi√ß√£o dos notebooks via ADF.


## üìÑ Estrutura√ß√£o do curso/projeto

O projeto consiste na obten√ß√£o dos dados da F√≥rmula 1 via API Ergast, e armazenando os dados em uma camada raw. Ap√≥s isso, s√£o criadas pipelines e c√≥digos para uma camada de processamento bem como uma camada de an√°lise. 
Todo o processo √© orquestrado via ADF, e, ao final de toda a esteira de dados, √© poss√≠vel realizar an√°lises no pr√≥prio Databricks e/ou utilizando o Power BI.

### üìÑ M√≥dulos

- Overviews
    - Portal Azure
    - Azure Databricks
    - Projeto
- Spark
	- Databricks
	- Clusters
	- Notebooks
	- DBFS
	- Jobs
- Spark (Python)
	- Ingest√£o 1
	- Ingest√£o 2
	- Ingest√£o 3
	- Transforma√ß√£o
	- Agrega√ß√µes
	- Carga Incremental
- Spark (SQL)
	- Views Tempor√°rias
	- DDL
	- DML
	- Analises
	- Cargas Incremental
- Delta Lake
	- Delta Lake
- Orquestra√ß√£o
	- Azure Data Factory
	- Outras ferramentas para conex√£o


### üì¶ Fontes de dados

As fontes dos dados s√£o da **Ergast** contendo informa√ß√µes das equipes, anos, pilotos, dentre outras.

### üíª Arquitetura proposta

<p align="center">
  <img src="imgs/img-01.png" />
</p>


## üë®‚Äçüéì Conclus√£o

Embora j√° possuo alguns conhecimentos nas ferramentas, gostaria de registrar que o curso proporciona uma abordagem pr√°tica proporcionando t√©cnicas e conceitos sobre Delta, cargas incrementais em PySpark e Spark SQL, dentre muitas outras funcionalidades que podem ser implementadas no dia a dia. Agrade√ßo imensamente ao instrutor por todos os conhecimentos abordados.

<p align="center">
 <a href="https://www.udemy.com/certificate/UC-aa454823-a814-4894-a52f-8a4382226cf3/">
    <img src="imgs/img-03.png" />
 </a>
</p>

Link do certificado: https://www.udemy.com/certificate/UC-aa454823-a814-4894-a52f-8a4382226cf3/




